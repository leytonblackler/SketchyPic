{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.14.0\n",
      "SciPy version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from glob import glob\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import skimage\n",
    "# from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import numpy\n",
    "import cv2\n",
    "# import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "import scipy\n",
    "from scipy import misc\n",
    "\n",
    "import imageio\n",
    "import argparse\n",
    "import sys\n",
    "# Will use matplotlib for showing the image\n",
    "from matplotlib import pyplot as plt\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"SciPy version: \" + scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Functions which need the PIL\n",
    "\n",
    "import numpy\n",
    "import tempfile\n",
    "\n",
    "from numpy import (amin, amax, ravel, asarray, arange, ones, newaxis,\n",
    "                   transpose, iscomplexobj, uint8, issubdtype, array)\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageFilter\n",
    "except ImportError:\n",
    "    import Image\n",
    "    import ImageFilter\n",
    "\n",
    "\n",
    "if not hasattr(Image, 'frombytes'):\n",
    "    Image.frombytes = Image.fromstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_samples_from_each_category = 15 # max 100\n",
    "sketch_samples_from_each_category = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"/local/scratch/blacklleyt/Semester2/sketchypic/256x256\"\n",
    "photo_folder = root_folder + \"/photo/tx_000100000000\"\n",
    "sketch_folder = root_folder + \"/sketch/tx_000100000000\"\n",
    "destination = \"/local/scratch/blacklleyt/Semester2/sketchypic/datasets\"\n",
    "salience_model = \"/local/scratch/blacklleyt/Semester2/sketchypic/salience_model\"\n",
    "segment_script = \"/local/scratch/blacklleyt/Semester2/sketchypic/segment/segment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_smoothing_value = 0.5\n",
    "threhold_function_value = 500\n",
    "minimum_component_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the names of each of the categories in the sketchy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category names:  ['chair', 'starfish', 'helicopter', 'cat', 'hermit_crab', 'banana', 'fish', 'hedgehog', 'airplane', 'guitar', 'frog', 'bell', 'lobster', 'seal', 'sailboat', 'duck', 'cup', 'pickup_truck', 'cabin', 'door', 'wine_bottle', 'candle', 'piano', 'camel', 'hat', 'violin', 'rocket', 'bicycle', 'pretzel', 'knife', 'raccoon', 'swan', 'pizza', 'hamburger', 'tiger', 'sheep', 'axe', 'teddy_bear', 'fan', 'ray', 'hot-air_balloon', 'racket', 'bear', 'volcano', 'tree', 'ant', 'scorpion', 'scissors', 'pineapple', 'owl', 'hammer', 'bread', 'teapot', 'table', 'alarm_clock', 'motorcycle', 'chicken', 'blimp', 'lion', 'crab', 'tank', 'jellyfish', 'strawberry', 'deer', 'rabbit', 'dog', 'squirrel', 'turtle', 'pear', 'apple', 'hotdog', 'penguin', 'armor', 'crocodilian', 'cow', 'car_(sedan)', 'ape', 'bat', 'hourglass', 'harp', 'castle', 'spider', 'pig', 'windmill', 'wheelchair', 'shoe', 'rifle', 'butterfly', 'wading_bird', 'bee', 'horse', 'sword', 'elephant', 'mushroom', 'trumpet', 'bench', 'kangaroo', 'snake', 'window', 'beetle', 'skyscraper', 'couch', 'umbrella', 'spoon', 'seagull', 'parrot', 'eyeglasses', 'geyser', 'zebra', 'jack-o-lantern', 'flower', 'giraffe', 'cannon', 'mouse', 'shark', 'church', 'songbird', 'sea_turtle', 'lizard', 'snail', 'saw', 'pistol', 'dolphin', 'saxophone', 'rhinoceros']\n"
     ]
    }
   ],
   "source": [
    "category_names = []\n",
    "for path in [f.path for f in os.scandir(photo_folder) if f.is_dir()]:\n",
    "    category_names.append(os.path.basename(path))\n",
    "print(\"category names: \", category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the file paths of the photo and sketch files to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_file_paths = []\n",
    "sketch_file_paths = []\n",
    "for category in category_names:\n",
    "    photo_category_folder_path = photo_folder + \"/\" + category\n",
    "    sketch_category_folder_path = sketch_folder + \"/\" + category\n",
    "    all_photos = glob(photo_category_folder_path + \"/*.jpg\")\n",
    "    all_sketches = glob(sketch_category_folder_path + \"/*.png\")\n",
    "    random.Random(1).shuffle(all_photos)\n",
    "    random.Random(1).shuffle(all_sketches)\n",
    "    photo_file_paths = photo_file_paths + all_photos[:photo_samples_from_each_category]\n",
    "    sketch_file_paths = sketch_file_paths + all_sketches[:sketch_samples_from_each_category]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the photos and sketches into collective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 1875\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "    \n",
    "print(\"length: \" + str(len(photo_file_paths)))\n",
    "    \n",
    "photo_destination = destination + \"/photo_original\"\n",
    "sketch_destination = destination + \"/sketch\"\n",
    "    \n",
    "if not os.path.exists(photo_destination):\n",
    "    os.makedirs(photo_destination)\n",
    "    \n",
    "if not os.path.exists(sketch_destination):\n",
    "    os.makedirs(sketch_destination)\n",
    "    \n",
    "for photo_path in photo_file_paths:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    shutil.copy(photo_path, photo_destination) \n",
    "    \n",
    "for sketch_path in sketch_file_paths:\n",
    "    filename = os.path.basename(sketch_path)\n",
    "    shutil.copy(sketch_path, sketch_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate salience maps for each of the photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromimage(im, flatten=False, mode=None):\n",
    "    if not Image.isImageType(im):\n",
    "        raise TypeError(\"Input is not a PIL image.\")\n",
    "\n",
    "    if mode is not None:\n",
    "        if mode != im.mode:\n",
    "            im = im.convert(mode)\n",
    "    elif im.mode == 'P':\n",
    "        # Mode 'P' means there is an indexed \"palette\".  If we leave the mode\n",
    "        # as 'P', then when we do `a = array(im)` below, `a` will be a 2-D\n",
    "        # containing the indices into the palette, and not a 3-D array\n",
    "        # containing the RGB or RGBA values.\n",
    "        if 'transparency' in im.info:\n",
    "            im = im.convert('RGBA')\n",
    "        else:\n",
    "            im = im.convert('RGB')\n",
    "\n",
    "    if flatten:\n",
    "        im = im.convert('F')\n",
    "    elif im.mode == '1':\n",
    "        # Workaround for crash in PIL. When im is 1-bit, the call array(im)\n",
    "        # can cause a seg. fault, or generate garbage. See\n",
    "        # https://github.com/scipy/scipy/issues/2138 and\n",
    "        # https://github.com/python-pillow/Pillow/issues/350.\n",
    "        #\n",
    "        # This converts im from a 1-bit image to an 8-bit image.\n",
    "        im = im.convert('L')\n",
    "\n",
    "    a = array(im)\n",
    "    return a\n",
    "\n",
    "\n",
    "def bytescale(data, cmin=None, cmax=None, high=255, low=0):\n",
    "    if data.dtype == uint8:\n",
    "        return data\n",
    "\n",
    "    if high > 255:\n",
    "        raise ValueError(\"`high` should be less than or equal to 255.\")\n",
    "    if low < 0:\n",
    "        raise ValueError(\"`low` should be greater than or equal to 0.\")\n",
    "    if high < low:\n",
    "        raise ValueError(\"`high` should be greater than or equal to `low`.\")\n",
    "\n",
    "    if cmin is None:\n",
    "        cmin = data.min()\n",
    "    if cmax is None:\n",
    "        cmax = data.max()\n",
    "\n",
    "    cscale = cmax - cmin\n",
    "    if cscale < 0:\n",
    "        raise ValueError(\"`cmax` should be larger than `cmin`.\")\n",
    "    elif cscale == 0:\n",
    "        cscale = 1\n",
    "\n",
    "    scale = float(high - low) / cscale\n",
    "    bytedata = (data - cmin) * scale + low\n",
    "    return (bytedata.clip(low, high) + 0.5).astype(uint8)\n",
    "\n",
    "\n",
    "def toimage(arr, high=255, low=0, cmin=None, cmax=None, pal=None,\n",
    "            mode=None, channel_axis=None):\n",
    "    \n",
    "    data = asarray(arr)\n",
    "    if iscomplexobj(data):\n",
    "        raise ValueError(\"Cannot convert a complex-valued array.\")\n",
    "    shape = list(data.shape)\n",
    "    valid = len(shape) == 2 or ((len(shape) == 3) and\n",
    "                                ((3 in shape) or (4 in shape)))\n",
    "    if not valid:\n",
    "        raise ValueError(\"'arr' does not have a suitable array shape for \"\n",
    "                         \"any mode.\")\n",
    "    if len(shape) == 2:\n",
    "        shape = (shape[1], shape[0])  # columns show up first\n",
    "        if mode == 'F':\n",
    "            data32 = data.astype(numpy.float32)\n",
    "            image = Image.frombytes(mode, shape, data32.tostring())\n",
    "            return image\n",
    "        if mode in [None, 'L', 'P']:\n",
    "            bytedata = bytescale(data, high=high, low=low,\n",
    "                                 cmin=cmin, cmax=cmax)\n",
    "            image = Image.frombytes('L', shape, bytedata.tostring())\n",
    "            if pal is not None:\n",
    "                image.putpalette(asarray(pal, dtype=uint8).tostring())\n",
    "                # Becomes a mode='P' automagically.\n",
    "            elif mode == 'P':  # default gray-scale\n",
    "                pal = (arange(0, 256, 1, dtype=uint8)[:, newaxis] *\n",
    "                       ones((3,), dtype=uint8)[newaxis, :])\n",
    "                image.putpalette(asarray(pal, dtype=uint8).tostring())\n",
    "            return image\n",
    "        if mode == '1':  # high input gives threshold for 1\n",
    "            bytedata = (data > high)\n",
    "            image = Image.frombytes('1', shape, bytedata.tostring())\n",
    "            return image\n",
    "        if cmin is None:\n",
    "            cmin = amin(ravel(data))\n",
    "        if cmax is None:\n",
    "            cmax = amax(ravel(data))\n",
    "        data = (data*1.0 - cmin)*(high - low)/(cmax - cmin) + low\n",
    "        if mode == 'I':\n",
    "            data32 = data.astype(numpy.uint32)\n",
    "            image = Image.frombytes(mode, shape, data32.tostring())\n",
    "        else:\n",
    "            raise ValueError(_errstr)\n",
    "        return image\n",
    "\n",
    "    # if here then 3-d array with a 3 or a 4 in the shape length.\n",
    "    # Check for 3 in datacube shape --- 'RGB' or 'YCbCr'\n",
    "    if channel_axis is None:\n",
    "        if (3 in shape):\n",
    "            ca = numpy.flatnonzero(asarray(shape) == 3)[0]\n",
    "        else:\n",
    "            ca = numpy.flatnonzero(asarray(shape) == 4)\n",
    "            if len(ca):\n",
    "                ca = ca[0]\n",
    "            else:\n",
    "                raise ValueError(\"Could not find channel dimension.\")\n",
    "    else:\n",
    "        ca = channel_axis\n",
    "\n",
    "    numch = shape[ca]\n",
    "    if numch not in [3, 4]:\n",
    "        raise ValueError(\"Channel axis dimension is not valid.\")\n",
    "\n",
    "    bytedata = bytescale(data, high=high, low=low, cmin=cmin, cmax=cmax)\n",
    "    if ca == 2:\n",
    "        strdata = bytedata.tostring()\n",
    "        shape = (shape[1], shape[0])\n",
    "    elif ca == 1:\n",
    "        strdata = transpose(bytedata, (0, 2, 1)).tostring()\n",
    "        shape = (shape[2], shape[0])\n",
    "    elif ca == 0:\n",
    "        strdata = transpose(bytedata, (1, 2, 0)).tostring()\n",
    "        shape = (shape[2], shape[1])\n",
    "    if mode is None:\n",
    "        if numch == 3:\n",
    "            mode = 'RGB'\n",
    "        else:\n",
    "            mode = 'RGBA'\n",
    "\n",
    "    if mode not in ['RGB', 'RGBA', 'YCbCr', 'CMYK']:\n",
    "        raise ValueError(_errstr)\n",
    "\n",
    "    if mode in ['RGB', 'YCbCr']:\n",
    "        if numch != 3:\n",
    "            raise ValueError(\"Invalid array shape for mode.\")\n",
    "    if mode in ['RGBA', 'CMYK']:\n",
    "        if numch != 4:\n",
    "            raise ValueError(\"Invalid array shape for mode.\")\n",
    "\n",
    "    # Here we know data and mode is correct\n",
    "    image = Image.frombytes(mode, shape, strdata)\n",
    "    return image\n",
    "\n",
    "def imresize(arr, size, interp='bilinear', mode=None):\n",
    "    im = toimage(arr, mode=mode)\n",
    "    ts = type(size)\n",
    "    if issubdtype(ts, numpy.signedinteger):\n",
    "        percent = size / 100.0\n",
    "        size = tuple((array(im.size)*percent).astype(int))\n",
    "    elif issubdtype(type(size), numpy.floating):\n",
    "        size = tuple((array(im.size)*size).astype(int))\n",
    "    else:\n",
    "        size = (size[1], size[0])\n",
    "    func = {'nearest': 0, 'lanczos': 1, 'bilinear': 2, 'bicubic': 3, 'cubic': 3}\n",
    "    imnew = im.resize(size, resample=func[interp])\n",
    "    return fromimage(imnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 13:54:10.096683 140501534275392 deprecation.py:323] From /usr/pkg/lib/python3.7/site-packages/tensorflow/python/training/queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0830 13:54:10.106972 140501534275392 deprecation.py:323] From /usr/pkg/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "photo_salience_map_destination = destination + \"/photo_salience_map\"\n",
    "    \n",
    "if not os.path.exists(photo_salience_map_destination):\n",
    "    os.makedirs(photo_salience_map_destination)\n",
    "\n",
    "g_mean = numpy.array(([126.88,120.24,112.19])).reshape([1,1,3])\n",
    "gpu_fraction = 1.0\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = gpu_fraction)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options = gpu_options)) as sess:\n",
    "    saver = tf.train.import_meta_graph(salience_model + '/meta_graph/my-model.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint(salience_model))\n",
    "    image_batch = tf.get_collection('image_batch')[0]\n",
    "    pred_mattes = tf.get_collection('mask')[0]\n",
    "    \n",
    "    for photo_path in photo_file_paths:\n",
    "        filename = os.path.basename(photo_path)\n",
    "        rgb = cv2.imread(photo_path)\n",
    "        if rgb.shape[2]==4:\n",
    "            rgb = rgba2rgb(rgb)\n",
    "        origin_shape = rgb.shape\n",
    "        rgb = numpy.expand_dims(imresize(rgb.astype(numpy.uint8),[320,320,3]).astype(numpy.float32)-g_mean,0)\n",
    "        feed_dict = {image_batch:rgb}\n",
    "        pred_alpha = sess.run(pred_mattes,feed_dict = feed_dict)\n",
    "        final_alpha = imresize(numpy.squeeze(pred_alpha),origin_shape)\n",
    "        cv2.imwrite((photo_salience_map_destination + \"/\" + filename),final_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_salience_binary_mask_destination = destination + \"/photo_salience_binary_mask\"\n",
    "\n",
    "if not os.path.exists(photo_salience_binary_mask_destination):\n",
    "    os.makedirs(photo_salience_binary_mask_destination)\n",
    "\n",
    "for photo_path in photo_file_paths:\n",
    "    filename = os.path.basename(photo_path)\n",
    "\n",
    "    image = cv2.imread(photo_salience_map_destination + \"/\" + filename, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    (thresh, im_bw) = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    before = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "    after = cv2.cvtColor(im_bw,cv2.COLOR_GRAY2RGB)\n",
    "    #plt.imshow(np.hstack((before,after)))\n",
    "\n",
    "    cv2.imwrite(photo_salience_binary_mask_destination + \"/\" + filename, im_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_salience_extracted = destination + \"/photo_salience_extracted\"\n",
    "\n",
    "if not os.path.exists(photo_salience_extracted):\n",
    "    os.makedirs(photo_salience_extracted)\n",
    "\n",
    "for photo_path in photo_file_paths:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    mask = cv2.imread(photo_salience_binary_mask_destination + \"/\" + filename, cv2.IMREAD_COLOR)\n",
    "    original = cv2.imread(photo_path, cv2.IMREAD_COLOR)\n",
    "    inverted_mask = cv2.bitwise_not(mask)\n",
    "    subject = cv2.bitwise_and(original, mask)\n",
    "    extracted = cv2.bitwise_or(subject, inverted_mask)\n",
    "    original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    original_and_mask = np.hstack((original_rgb, mask))\n",
    "    extracted_rgb = cv2.cvtColor(extracted, cv2.COLOR_BGR2RGB)\n",
    "    original_and_mask_and_extracted = np.hstack((original_and_mask, extracted_rgb))\n",
    "    \n",
    "#     cv2.imwrite(photo_salience_extracted + \"/\" + filename, extracted)\n",
    "    final = Image.fromarray(cv2.cvtColor(extracted, cv2.COLOR_BGR2RGB))\n",
    "    final.save(photo_salience_extracted + \"/\" + filename_without_extension + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the JPEG photo files to PPM as preparation for segment detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "    \n",
    "photo_ppm_destination = destination + \"/photo_ppm\"\n",
    "    \n",
    "if not os.path.exists(photo_ppm_destination):\n",
    "    os.makedirs(photo_ppm_destination)\n",
    "    \n",
    "for photo_path in photo_file_paths:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    photo = Image.open(photo_salience_extracted + \"/\" + filename_without_extension + \".png\")\n",
    "    photo.save(photo_ppm_destination + \"/\" + filename_without_extension + \".ppm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform segment detection on the photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "    \n",
    "photo_segment_ppm_destination = destination + \"/photo_segments_ppm\"\n",
    "    \n",
    "if not os.path.exists(photo_segment_ppm_destination):\n",
    "    os.makedirs(photo_segment_ppm_destination)\n",
    "    \n",
    "ppm_photos = glob(photo_ppm_destination + \"/*.ppm\")\n",
    "\n",
    "for photo_path in ppm_photos:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    output_file = photo_segment_ppm_destination + \"/\" + filename\n",
    "    bash_command = \"/local/scratch/blacklleyt/Semester2/sketchypic/segment/segment \"\n",
    "    bash_command = bash_command + str(sigma_smoothing_value) + \" \"\n",
    "    bash_command = bash_command + str(threhold_function_value) + \" \"\n",
    "    bash_command = bash_command + str(minimum_component_size) + \" \"\n",
    "    bash_command = bash_command + photo_path + \" \" + output_file\n",
    "    os.system(bash_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the PPM segment files into PNG image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_segment_destination = destination + \"/photo_segments\"\n",
    "    \n",
    "if not os.path.exists(photo_segment_destination):\n",
    "    os.makedirs(photo_segment_destination)\n",
    "    \n",
    "photo_segment_ppm_photos = glob(photo_segment_ppm_destination + \"/*.ppm\")\n",
    "    \n",
    "for photo_path in photo_segment_ppm_photos:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    photo = Image.open(photo_path)\n",
    "    photo.save(photo_segment_destination + \"/\" + filename_without_extension + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# photo_segment_blurred_destination = destination + \"/photo_segment_blurred_destination\"\n",
    "    \n",
    "# if not os.path.exists(photo_segment_blurred_destination):\n",
    "#     os.makedirs(photo_segment_blurred_destination)\n",
    "    \n",
    "# photo_segment_photos = glob(photo_segment_destination + \"/*.png\")\n",
    "    \n",
    "# for photo_path in photo_segment_photos:\n",
    "#     filename = os.path.basename(photo_path)\n",
    "#     filename_without_extension = os.path.splitext(filename)[0]\n",
    "#     photo = Image.open(photo_path)\n",
    "#     blurred = photo.filter(ImageFilter.GaussianBlur(radius=1))\n",
    "#     blurred.save(photo_segment_blurred_destination + \"/\" + filename_without_extension + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Sobel operator to the detected segment images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_segment_sobel_destination = destination + \"/photo_segment_sobel_destination\"\n",
    "    \n",
    "if not os.path.exists(photo_segment_sobel_destination):\n",
    "    os.makedirs(photo_segment_sobel_destination)\n",
    "    \n",
    "photo_segment_photos = glob(photo_segment_destination + \"/*.png\")\n",
    "    \n",
    "for photo_path in photo_segment_photos:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    image = cv2.imread(photo_path)\n",
    "    image = image.astype('int32')\n",
    "    dx = scipy.ndimage.sobel(image, 0)  # horizontal derivative\n",
    "    dy = scipy.ndimage.sobel(image, 1)  # vertical derivative\n",
    "    mag = numpy.hypot(dx, dy)  # magnitude\n",
    "    mag *= 255.0 / numpy.max(mag)  # normalize (Q&D)\n",
    "    cv2.imwrite(photo_segment_sobel_destination + \"/\" + filename, mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invert the output from from the Sobel filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "\n",
    "photo_segment_sobel_inverted_destination = destination + \"/photo_segment_sobel_inverted_destination\"\n",
    "    \n",
    "if not os.path.exists(photo_segment_sobel_inverted_destination):\n",
    "    os.makedirs(photo_segment_sobel_inverted_destination)\n",
    "    \n",
    "photo_segment_sobel_photos = glob(photo_segment_sobel_destination + \"/*.png\")\n",
    "    \n",
    "for photo_path in photo_segment_sobel_photos:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    image = cv2.imread(photo_path)\n",
    "    image = cv2.bitwise_not(image)\n",
    "    cv2.imwrite(photo_segment_sobel_inverted_destination + \"/\" + filename, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = destination + \"/train\"\n",
    "test_folder = destination + \"/test\"\n",
    "\n",
    "photo_train_folder = train_folder + \"/photo\"\n",
    "photo_test_folder = test_folder + \"/photo\"\n",
    "\n",
    "sketch_train_folder = train_folder + \"/sketch\"\n",
    "\n",
    "if not os.path.exists(train_folder):\n",
    "    os.makedirs(train_folder)\n",
    "    \n",
    "if not os.path.exists(test_folder):\n",
    "    os.makedirs(test_folder)\n",
    "    \n",
    "if not os.path.exists(photo_train_folder):\n",
    "    os.makedirs(photo_train_folder)\n",
    "    \n",
    "if not os.path.exists(photo_test_folder):\n",
    "    os.makedirs(photo_test_folder)\n",
    "    \n",
    "if not os.path.exists(sketch_train_folder):\n",
    "    os.makedirs(sketch_train_folder)\n",
    "\n",
    "# all_photos = glob(photo_salience_extracted + \"/*.png\")\n",
    "all_photos = glob(photo_segment_sobel_inverted_destination + \"/*.png\")\n",
    "all_sketches = glob(sketch_destination + \"/*.png\")\n",
    "\n",
    "random.Random(2).shuffle(all_photos)\n",
    "\n",
    "split = int(round(0.04 * len(all_photos)))\n",
    "\n",
    "train_photos = all_photos[split:]\n",
    "test_photos = all_photos[:split]\n",
    "\n",
    "for photo_path in train_photos:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    shutil.copy(photo_path, photo_train_folder) \n",
    "    \n",
    "for photo_path in test_photos:\n",
    "    filename = os.path.basename(photo_path)\n",
    "    shutil.copy(photo_path, photo_test_folder) \n",
    "    \n",
    "for sketch_path in all_sketches:\n",
    "    filename = os.path.basename(sketch_path)\n",
    "    shutil.copy(sketch_path, sketch_train_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
